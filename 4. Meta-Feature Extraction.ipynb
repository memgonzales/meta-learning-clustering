{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-feature Extraction\n",
    "\n",
    "**Mark Edward M. Gonzales, Lorene C. Uy, and Jacob Adrianne L. Sy (CSC713M)**<br>\n",
    "mark_gonzales@dlsu.edu.ph, lorene_c_uy@dlsu.edu.ph, jacob_adrianne_l_sy@dlsu.edu.ph\n",
    "\n",
    "In partial fulfillment of the requirements for the Machine Learning graduate class (CSC713M) under **Dr. Macario O. Cordel, II** of the Department of Computer Technology, College of Computer Studies, De La Salle University, this notebook details the process and presents the code for the **meta-feature extraction** stage of the investigatory project titled \"Automatic Recommendation of Distance Metric for $k$-Means Clustering: A Meta-Learning Approach.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART I: Preliminaries\n",
    "\n",
    "The following libraries and modules — most of which are automatically bundled with an Anaconda installation — were used in this notebook:\n",
    "\n",
    "Library/Module | Description | License\n",
    ":-- | :-- | :--\n",
    "<a href = \"https://docs.python.org/3/library/os.html\">`os`</a> | Provides miscellaneous operating system interfaces | Python Software Foundation License\n",
    "<a href = \"https://pandas.pydata.org/\">`pandas`</a> | Provides functions for data analysis and manipulation\t | BSD 3-Clause \"New\" or \"Revised\" License\n",
    "<a href = \"https://numpy.org/\">`numpy`</a> | Provides a multidimensional array object, various derived objects, and an assortment of routines for fast operations on arrays | BSD 3-Clause \"New\" or \"Revised\" License\n",
    "<a href = \"https://scikit-learn.org/stable/\">`scikit-learn`</a> | Python module for machine learning and predictive data analysis | BSD 3-Clause \"New\" or \"Revised\" License\n",
    "<a href = \"https://pymfe.readthedocs.io/en/latest/index.html\">`pymfe`</a> | Provides a functions for extracting different metafeatures based on various literatures | MIT License\n",
    "\n",
    "*The descriptions were lifted from their respective websites.*\n",
    "<br><br>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b>  The pymfe library is not included in Anaconda by default. The simplest way to install the library is to use pip by running the following command on the command prompt: <br>\n",
    "\n",
    "**`pip install -U pymfe`**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from pymfe.mfe import MFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART II: Meta-feature Extraction\n",
    "\n",
    "Metafeatures belonging to the following categories: **`general`**, **`statistical`**, **`information-theoretic`**, **`complexity`**, and **`structural`** were extracted.\n",
    "\n",
    "**general** <br>\n",
    "> These meta-features describe the dimensionality and size of the dataset\n",
    "\n",
    "**statistical** <br>\n",
    "> These meta-features capture characteristics related to feature interdependence, normality, degree of discreteness, and noisiness\n",
    "\n",
    "**information-theoretic** <br>\n",
    "> these meta-features quantify feature informativeness and interdependence\n",
    "\n",
    "**complexity** <br>\n",
    "> these meta-features pertain to attributes that are related to the principal component analysis (PCA) dimensions\n",
    "\n",
    "**structural** <br>\n",
    "> these meta-features capture patterns, statistics, and correlation information from the frequencies of *k*-itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_HEADER = r'noheader'\n",
    "\n",
    "folder = 'final_datasets'\n",
    "datasets = listdir(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General, Statistical, Information-Theoretic & Complexity Meta-Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = None\n",
    "row_data = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    # Some of the datasets are not encoded in the default UTF-8.\n",
    "    if re.search(NO_HEADER, dataset):\n",
    "        data_raw = pd.read_csv(f\"{folder}/{dataset}\", encoding='latin-1', header = None)\n",
    "    else:\n",
    "        data_raw = pd.read_csv(f\"{folder}/{dataset}\", encoding='latin-1')\n",
    "    \n",
    "    data = data_raw.to_numpy()    \n",
    "    X, y = np.split(data, [-1], axis=1)\n",
    "\n",
    "    # Data imputation\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    X = imp.fit_transform(X)\n",
    "    # Min-max normalization to [0, 1]\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # Extract general, statistical and information-theoretic measures.\n",
    "    mfe = MFE(  groups=[\"general\", \"statistical\", \"info-theory\", \"complexity\"], \n",
    "                features=[  \"attr_to_inst\", \"inst_to_attr\", \"nr_attr\", \"nr_bin\",\n",
    "                            \"nr_inst\", \"attr_conc\", \"attr_ent\", \"t2\", \"t3\", \"t4\", \"can_cor\", \n",
    "                            \"cor\", \"cov\", \"eigenvalues\", \"iq_range\", \"kurtosis\", \"mad\",  \n",
    "                            \"mean\", \"median\", \"nr_cor_attr\", \"nr_outliers\", \"sd\",\n",
    "                            \"skewness\", \"sparsity\", \"t_mean\", \"var\"]\n",
    "    )\n",
    "    mfe.fit(X, y)\n",
    "    ft = mfe.extract()\n",
    " \n",
    "    #ft[0] represents headers, initialize once \n",
    "    if(columns == None):\n",
    "        columns = ft[0] \n",
    "        \n",
    "    # create file paths\n",
    "    filename, ext = dataset.rsplit('.', 1)\n",
    "    ft[1].insert(0, filename)    \n",
    "    row_data.append(ft[1])\n",
    "    \n",
    "    print(dataset)\n",
    "    \n",
    "#add dataset to columns\n",
    "columns.insert(0, \"dataset\")\n",
    "metafeatures_df = pd.DataFrame(data=row_data, columns=columns)\n",
    "filename =  f\"./metafeatures_gsic.csv\"\n",
    "\n",
    "# Save data to CSV.\n",
    "metafeatures_df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structural Meta-Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = None\n",
    "row_data = []\n",
    "\n",
    "for dataset in datasets:        \n",
    "    # Some of the datasets are not encoded in the default UTF-8.\n",
    "    if re.search(NO_HEADER, dataset):\n",
    "        data_raw = pd.read_csv(f\"{folder}/{dataset}\", encoding='latin-1', header = None)\n",
    "    else:\n",
    "        data_raw = pd.read_csv(f\"{folder}/{dataset}\", encoding='latin-1')\n",
    "        \n",
    "    data = data_raw.to_numpy()    \n",
    "    X, y = np.split(data, [-1], axis=1)\n",
    "\n",
    "    # Data imputation\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    X = imp.fit_transform(X)\n",
    "    # Min-max normalization to [0, 1]\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    # Extract general, statistical and information-theoretic measures\n",
    "    mfe = MFE(  groups=\"all\", \n",
    "                features=[\"one_itemset\", \"two_itemset\"], summary=[\"quantiles\"]\n",
    "    )\n",
    "    mfe.fit(X, y)\n",
    "    ft = mfe.extract()\n",
    "\n",
    "    #ft[0] represents headers, initialize once \n",
    "    if(columns == None):\n",
    "        columns = ft[0] \n",
    "        \n",
    "    # create file paths\n",
    "    filename, ext = dataset.rsplit('.', 1)\n",
    "    ft[1].insert(0, filename)    \n",
    "    row_data.append(ft[1])\n",
    "    \n",
    "    print(dataset)\n",
    "\n",
    "#add dataset to columns\n",
    "columns.insert(0, \"dataset\")\n",
    "metafeatures_df = pd.DataFrame(data=row_data, columns=columns)\n",
    "filename =  f\"./metafeatures_itemset.csv\"\n",
    "\n",
    "# Save data to CSV.\n",
    "metafeatures_df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Consolidation of Meta-Features\n",
    "\n",
    "The consolidated csv output contains the meta-features for each dataset and their corresponding evaluation following the result of the dataset labeling stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data containing information on general, statistical, information-theoretic, and complexity meta-features\n",
    "gsic = pd.read_csv('metafeatures_gsic.csv')\n",
    "gsic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data containing information on structural meta-features\n",
    "structural = pd.read_csv('metafeatures_itemset.csv')\n",
    "structural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consolidated meta-features\n",
    "mf_no_label = pd.concat([gsic, structural], axis=1, join='inner')\n",
    "mf_no_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>best_dist_metric_ari</th>\n",
       "      <th>best_dist_metric_dbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1_raw</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>euclidean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a1_va3</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>euclidean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a2_raw</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>chebyshev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a2_va3</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a3_raw</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>euclidean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>winequality-white</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>euclidean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>wine</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>euclidean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>wisconsin</td>\n",
       "      <td>mahalanobis</td>\n",
       "      <td>manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Zemberek-Stemmed</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>zoo_one_hot</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>chebyshev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               dataset best_dist_metric_ari best_dist_metric_dbs\n",
       "0               a1_raw            manhattan            euclidean\n",
       "1               a1_va3            euclidean            euclidean\n",
       "2               a2_raw            euclidean            chebyshev\n",
       "3               a2_va3            euclidean            manhattan\n",
       "4               a3_raw            euclidean            euclidean\n",
       "..                 ...                  ...                  ...\n",
       "335  winequality-white            euclidean            euclidean\n",
       "336               wine            euclidean            euclidean\n",
       "337          wisconsin          mahalanobis            manhattan\n",
       "338   Zemberek-Stemmed            euclidean            manhattan\n",
       "339        zoo_one_hot            manhattan            chebyshev\n",
       "\n",
       "[340 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation metrics derived from data labeling stage\n",
    "metrics =  pd.read_csv('dataset_labels/csv_collated/results_top_metrics.csv')\n",
    "metrics = metrics[['dataset', 'best_dist_metric_ari', 'best_dist_metric_dbs']]\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = pd.concat([mf_no_label, metrics], axis=1, join='inner')\n",
    "mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_data = mf.to_numpy()    \n",
    "X, y = np.split(mf_data, [-2], axis=1)\n",
    "\n",
    "# Data imputation\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X = imp.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = list(mf.columns.values)\n",
    "\n",
    "mf_final = pd.DataFrame(np.concatenate((X, y), axis=1))\n",
    "mf_final.columns = header\n",
    "mf_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_final.to_csv('dataset_labels/metafeatures.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attr_conc.mean</th>\n",
       "      <th>attr_conc.sd</th>\n",
       "      <th>attr_ent.mean</th>\n",
       "      <th>attr_ent.sd</th>\n",
       "      <th>attr_to_inst</th>\n",
       "      <th>can_cor.mean</th>\n",
       "      <th>can_cor.sd</th>\n",
       "      <th>cor.mean</th>\n",
       "      <th>cor.sd</th>\n",
       "      <th>cov.mean</th>\n",
       "      <th>...</th>\n",
       "      <th>one_itemset.quantiles.2</th>\n",
       "      <th>one_itemset.quantiles.3</th>\n",
       "      <th>one_itemset.quantiles.4</th>\n",
       "      <th>two_itemset.quantiles.0</th>\n",
       "      <th>two_itemset.quantiles.1</th>\n",
       "      <th>two_itemset.quantiles.2</th>\n",
       "      <th>two_itemset.quantiles.3</th>\n",
       "      <th>two_itemset.quantiles.4</th>\n",
       "      <th>best_dist_metric_ari</th>\n",
       "      <th>best_dist_metric_dbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.083137</td>\n",
       "      <td>0.074754</td>\n",
       "      <td>3.584954</td>\n",
       "      <td>2.680000e-06</td>\n",
       "      <td>0.010303</td>\n",
       "      <td>0.433018</td>\n",
       "      <td>0.253195</td>\n",
       "      <td>0.242233</td>\n",
       "      <td>0.228001</td>\n",
       "      <td>0.006188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083572</td>\n",
       "      <td>0.083572</td>\n",
       "      <td>0.084144</td>\n",
       "      <td>0.010303</td>\n",
       "      <td>0.147682</td>\n",
       "      <td>0.155695</td>\n",
       "      <td>0.161420</td>\n",
       "      <td>0.167716</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>euclidean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.037992</td>\n",
       "      <td>0.036260</td>\n",
       "      <td>3.584956</td>\n",
       "      <td>1.400000e-06</td>\n",
       "      <td>0.018359</td>\n",
       "      <td>0.217562</td>\n",
       "      <td>0.399361</td>\n",
       "      <td>0.125801</td>\n",
       "      <td>0.172071</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083190</td>\n",
       "      <td>0.083764</td>\n",
       "      <td>0.083764</td>\n",
       "      <td>0.027539</td>\n",
       "      <td>0.148021</td>\n",
       "      <td>0.153758</td>\n",
       "      <td>0.158921</td>\n",
       "      <td>0.167527</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>euclidean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.086459</td>\n",
       "      <td>0.064692</td>\n",
       "      <td>3.321917</td>\n",
       "      <td>4.570000e-16</td>\n",
       "      <td>0.014241</td>\n",
       "      <td>0.477469</td>\n",
       "      <td>0.210690</td>\n",
       "      <td>0.220614</td>\n",
       "      <td>0.217854</td>\n",
       "      <td>0.005883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099684</td>\n",
       "      <td>0.100475</td>\n",
       "      <td>0.100475</td>\n",
       "      <td>0.011076</td>\n",
       "      <td>0.172468</td>\n",
       "      <td>0.183544</td>\n",
       "      <td>0.193038</td>\n",
       "      <td>0.200949</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>chebyshev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.046616</td>\n",
       "      <td>0.036637</td>\n",
       "      <td>3.321928</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.025397</td>\n",
       "      <td>-0.014967</td>\n",
       "      <td>0.440451</td>\n",
       "      <td>0.125810</td>\n",
       "      <td>0.176909</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.034921</td>\n",
       "      <td>0.173016</td>\n",
       "      <td>0.182540</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.101427</td>\n",
       "      <td>0.026079</td>\n",
       "      <td>3.584958</td>\n",
       "      <td>2.430000e-06</td>\n",
       "      <td>0.009815</td>\n",
       "      <td>0.316617</td>\n",
       "      <td>0.442044</td>\n",
       "      <td>0.272287</td>\n",
       "      <td>0.228004</td>\n",
       "      <td>0.008253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083424</td>\n",
       "      <td>0.083424</td>\n",
       "      <td>0.083969</td>\n",
       "      <td>0.002181</td>\n",
       "      <td>0.147219</td>\n",
       "      <td>0.157579</td>\n",
       "      <td>0.163577</td>\n",
       "      <td>0.167394</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>euclidean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>0.023432</td>\n",
       "      <td>0.021466</td>\n",
       "      <td>3.444974</td>\n",
       "      <td>1.128371e-02</td>\n",
       "      <td>0.006879</td>\n",
       "      <td>0.369102</td>\n",
       "      <td>0.550237</td>\n",
       "      <td>0.199823</td>\n",
       "      <td>0.188264</td>\n",
       "      <td>0.003710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090056</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.151970</td>\n",
       "      <td>0.081301</td>\n",
       "      <td>0.153221</td>\n",
       "      <td>0.164478</td>\n",
       "      <td>0.175735</td>\n",
       "      <td>0.249531</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>euclidean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.014634</td>\n",
       "      <td>0.017273</td>\n",
       "      <td>3.973324</td>\n",
       "      <td>2.244442e-02</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>0.133160</td>\n",
       "      <td>0.283442</td>\n",
       "      <td>0.178266</td>\n",
       "      <td>0.189298</td>\n",
       "      <td>0.001608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062372</td>\n",
       "      <td>0.067630</td>\n",
       "      <td>0.109024</td>\n",
       "      <td>0.041854</td>\n",
       "      <td>0.107595</td>\n",
       "      <td>0.116987</td>\n",
       "      <td>0.125970</td>\n",
       "      <td>0.192119</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>euclidean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>0.080498</td>\n",
       "      <td>0.076914</td>\n",
       "      <td>2.320541</td>\n",
       "      <td>7.082206e-03</td>\n",
       "      <td>0.159794</td>\n",
       "      <td>0.492791</td>\n",
       "      <td>0.322741</td>\n",
       "      <td>0.314237</td>\n",
       "      <td>0.259968</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201031</td>\n",
       "      <td>0.201031</td>\n",
       "      <td>0.257732</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.298969</td>\n",
       "      <td>0.319588</td>\n",
       "      <td>0.345361</td>\n",
       "      <td>0.412371</td>\n",
       "      <td>mahalanobis</td>\n",
       "      <td>manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.006221</td>\n",
       "      <td>0.066647</td>\n",
       "      <td>1.487167e-01</td>\n",
       "      <td>1.581550</td>\n",
       "      <td>0.217634</td>\n",
       "      <td>0.305870</td>\n",
       "      <td>0.007252</td>\n",
       "      <td>0.029346</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.998055</td>\n",
       "      <td>0.999722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006946</td>\n",
       "      <td>0.393998</td>\n",
       "      <td>0.993054</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>0.211544</td>\n",
       "      <td>0.255661</td>\n",
       "      <td>0.685161</td>\n",
       "      <td>4.143190e-01</td>\n",
       "      <td>0.306931</td>\n",
       "      <td>0.997751</td>\n",
       "      <td>0.322741</td>\n",
       "      <td>0.287380</td>\n",
       "      <td>0.242389</td>\n",
       "      <td>0.055993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559406</td>\n",
       "      <td>0.747525</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.386139</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.613861</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>chebyshev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     attr_conc.mean  attr_conc.sd  attr_ent.mean   attr_ent.sd  attr_to_inst  \\\n",
       "0          0.083137      0.074754       3.584954  2.680000e-06      0.010303   \n",
       "1          0.037992      0.036260       3.584956  1.400000e-06      0.018359   \n",
       "2          0.086459      0.064692       3.321917  4.570000e-16      0.014241   \n",
       "3          0.046616      0.036637       3.321928  0.000000e+00      0.025397   \n",
       "4          0.101427      0.026079       3.584958  2.430000e-06      0.009815   \n",
       "..              ...           ...            ...           ...           ...   \n",
       "335        0.023432      0.021466       3.444974  1.128371e-02      0.006879   \n",
       "336        0.014634      0.017273       3.973324  2.244442e-02      0.002246   \n",
       "337        0.080498      0.076914       2.320541  7.082206e-03      0.159794   \n",
       "338        0.000976      0.006221       0.066647  1.487167e-01      1.581550   \n",
       "339        0.211544      0.255661       0.685161  4.143190e-01      0.306931   \n",
       "\n",
       "     can_cor.mean  can_cor.sd  cor.mean    cor.sd  cov.mean  ...  \\\n",
       "0        0.433018    0.253195  0.242233  0.228001  0.006188  ...   \n",
       "1        0.217562    0.399361  0.125801  0.172071  0.000761  ...   \n",
       "2        0.477469    0.210690  0.220614  0.217854  0.005883  ...   \n",
       "3       -0.014967    0.440451  0.125810  0.176909  0.000887  ...   \n",
       "4        0.316617    0.442044  0.272287  0.228004  0.008253  ...   \n",
       "..            ...         ...       ...       ...       ...  ...   \n",
       "335      0.369102    0.550237  0.199823  0.188264  0.003710  ...   \n",
       "336      0.133160    0.283442  0.178266  0.189298  0.001608  ...   \n",
       "337      0.492791    0.322741  0.314237  0.259968  0.009200  ...   \n",
       "338      0.217634    0.305870  0.007252  0.029346  0.000010  ...   \n",
       "339      0.997751    0.322741  0.287380  0.242389  0.055993  ...   \n",
       "\n",
       "     one_itemset.quantiles.2  one_itemset.quantiles.3  \\\n",
       "0                   0.083572                 0.083572   \n",
       "1                   0.083190                 0.083764   \n",
       "2                   0.099684                 0.100475   \n",
       "3                   0.100000                 0.100000   \n",
       "4                   0.083424                 0.083424   \n",
       "..                       ...                      ...   \n",
       "335                 0.090056                 0.097561   \n",
       "336                 0.062372                 0.067630   \n",
       "337                 0.201031                 0.201031   \n",
       "338                 0.067797                 0.998055   \n",
       "339                 0.559406                 0.747525   \n",
       "\n",
       "     one_itemset.quantiles.4  two_itemset.quantiles.0  \\\n",
       "0                   0.084144                 0.010303   \n",
       "1                   0.083764                 0.027539   \n",
       "2                   0.100475                 0.011076   \n",
       "3                   0.100000                 0.034921   \n",
       "4                   0.083969                 0.002181   \n",
       "..                       ...                      ...   \n",
       "335                 0.151970                 0.081301   \n",
       "336                 0.109024                 0.041854   \n",
       "337                 0.257732                 0.010309   \n",
       "338                 0.999722                 0.000000   \n",
       "339                 1.000000                 0.000000   \n",
       "\n",
       "     two_itemset.quantiles.1  two_itemset.quantiles.2  \\\n",
       "0                   0.147682                 0.155695   \n",
       "1                   0.148021                 0.153758   \n",
       "2                   0.172468                 0.183544   \n",
       "3                   0.173016                 0.182540   \n",
       "4                   0.147219                 0.157579   \n",
       "..                       ...                      ...   \n",
       "335                 0.153221                 0.164478   \n",
       "336                 0.107595                 0.116987   \n",
       "337                 0.298969                 0.319588   \n",
       "338                 0.006946                 0.393998   \n",
       "339                 0.386139                 0.500000   \n",
       "\n",
       "     two_itemset.quantiles.3  two_itemset.quantiles.4  best_dist_metric_ari  \\\n",
       "0                   0.161420                 0.167716             manhattan   \n",
       "1                   0.158921                 0.167527             euclidean   \n",
       "2                   0.193038                 0.200949             euclidean   \n",
       "3                   0.190476                 0.200000             euclidean   \n",
       "4                   0.163577                 0.167394             euclidean   \n",
       "..                       ...                      ...                   ...   \n",
       "335                 0.175735                 0.249531             euclidean   \n",
       "336                 0.125970                 0.192119             euclidean   \n",
       "337                 0.345361                 0.412371           mahalanobis   \n",
       "338                 0.993054                 1.000000             euclidean   \n",
       "339                 0.613861                 1.000000             manhattan   \n",
       "\n",
       "     best_dist_metric_dbs  \n",
       "0               euclidean  \n",
       "1               euclidean  \n",
       "2               chebyshev  \n",
       "3               manhattan  \n",
       "4               euclidean  \n",
       "..                    ...  \n",
       "335             euclidean  \n",
       "336             euclidean  \n",
       "337             manhattan  \n",
       "338             manhattan  \n",
       "339             chebyshev  \n",
       "\n",
       "[340 rows x 54 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm = pd.read_csv('dataset_labels/metafeatures.csv')\n",
    "mm['best_dist_metric_dbs'] = metrics['best_dist_metric_dbs']\n",
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.to_csv('dataset_labels/metafeatures1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
