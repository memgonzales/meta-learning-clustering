{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Metric Recommendation for $k$-Means Clustering: A Meta-Learning Approach\n",
    "\n",
    "**Mark Edward M. Gonzales<sup>1</sup>, Lorene C. Uy<sup>1</sup>, Jacob Adrianne L. Sy<sup>1</sup>, Macario O. Cordel, II<sup>2</sup>**\n",
    "\n",
    "<sup>1</sup> Department of Software Technology, College of Computer Studies, De La Salle University <br>\n",
    "<sup>2</sup> Department of Computer Technology, College of Computer Studies, De La Salle University \n",
    "\n",
    "{mark_gonzales, lorene_c_uy, jacob_adrianne_l_sy, macario.cordel}@dlsu.edu.ph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART I: Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following libraries and modules — most of which are automatically bundled with an Anaconda installation — were used in this notebook:\n",
    "\n",
    "Library/Module | Description | License\n",
    ":-- | :-- | :--\n",
    "<a href = \"https://docs.python.org/3/library/os.html\">`os`</a> | Provides miscellaneous operating system interfaces | Python Software Foundation License\n",
    "<a href = \"https://pandas.pydata.org/\">`pandas`</a> | Provides functions for data analysis and manipulation\t | BSD 3-Clause \"New\" or \"Revised\" License\n",
    "<a href = \"https://numpy.org/\">`numpy`</a> | Provides a multidimensional array object, various derived objects, and an assortment of routines for fast operations on arrays | BSD 3-Clause \"New\" or \"Revised\" License\n",
    "<a href = \"https://scikit-learn.org/stable/\">`scikit-learn`</a> | Python module for machine learning and predictive data analysis | BSD 3-Clause \"New\" or \"Revised\" License\n",
    "<a href = \"https://pymfe.readthedocs.io/en/latest/index.html\">`pymfe`</a> | Provides a functions for extracting different metafeatures based on various literatures | MIT License\n",
    "\n",
    "*The descriptions were lifted from their respective websites.*\n",
    "<br><br>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b>  The <a href = \"https://pymfe.readthedocs.io/en/latest/index.html\"><code>pymfe</code></a> library is not included in Anaconda by default. The fastest way to install this library is to use pip and run the following command on the terminal: <br>\n",
    "\n",
    "**`pip install -U pymfe`**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from pymfe.mfe import MFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART II: Meta-feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metafeatures belonging to the **`general`**, **`statistical`**, **`information-theoretic`**, **`complexity`**, and **`structural`** categories were extracted.\n",
    "\n",
    "**General** <br>\n",
    "> These meta-features describe the dimensionality and size of the dataset\n",
    "\n",
    "**Statistical** <br>\n",
    "> These meta-features capture characteristics related to feature interdependence, normality, degree of discreteness, and noisiness\n",
    "\n",
    "**Information-Theoretic** <br>\n",
    "> These meta-features quantify feature informativeness and interdependence\n",
    "\n",
    "**Complexity** <br>\n",
    "> These meta-features pertain to attributes that are related to the principal component analysis (PCA) dimensions\n",
    "\n",
    "**Structural** <br>\n",
    "> These meta-features capture patterns, statistics, and correlation information from the frequencies of *k*-itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_HEADER = r'noheader'\n",
    "\n",
    "folder = 'final_datasets'\n",
    "datasets = listdir(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General, Statistical, Information-Theoretic & Complexity Meta-Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = None\n",
    "row_data = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    # Some of the datasets are not encoded in the default UTF-8.\n",
    "    if re.search(NO_HEADER, dataset):\n",
    "        data_raw = pd.read_csv(f\"{folder}/{dataset}\", encoding='latin-1', header = None)\n",
    "    else:\n",
    "        data_raw = pd.read_csv(f\"{folder}/{dataset}\", encoding='latin-1')\n",
    "    \n",
    "    data = data_raw.to_numpy()    \n",
    "    X, y = np.split(data, [-1], axis=1)\n",
    "\n",
    "    # Data imputation\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    X = imp.fit_transform(X)\n",
    "    # Min-max normalization to [0, 1]\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # Extract general, statistical and information-theoretic measures.\n",
    "    mfe = MFE(  groups=[\"general\", \"statistical\", \"info-theory\", \"complexity\"], \n",
    "                features=[  \"attr_to_inst\", \"inst_to_attr\", \"nr_attr\", \"nr_bin\",\n",
    "                            \"nr_inst\", \"attr_conc\", \"attr_ent\", \"t2\", \"t3\", \"t4\", \"can_cor\", \n",
    "                            \"cor\", \"cov\", \"eigenvalues\", \"iq_range\", \"kurtosis\", \"mad\",  \n",
    "                            \"mean\", \"median\", \"nr_cor_attr\", \"nr_outliers\", \"sd\",\n",
    "                            \"skewness\", \"sparsity\", \"t_mean\", \"var\"]\n",
    "    )\n",
    "    mfe.fit(X, y)\n",
    "    ft = mfe.extract()\n",
    " \n",
    "    #ft[0] represents headers, initialize once \n",
    "    if(columns == None):\n",
    "        columns = ft[0] \n",
    "        \n",
    "    # create file paths\n",
    "    filename, ext = dataset.rsplit('.', 1)\n",
    "    ft[1].insert(0, filename)    \n",
    "    row_data.append(ft[1])\n",
    "    \n",
    "    print(dataset)\n",
    "    \n",
    "#add dataset to columns\n",
    "columns.insert(0, \"dataset\")\n",
    "metafeatures_df = pd.DataFrame(data=row_data, columns=columns)\n",
    "filename =  f\"./metafeatures_gsic.csv\"\n",
    "\n",
    "# Save data to CSV.\n",
    "metafeatures_df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structural Meta-Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = None\n",
    "row_data = []\n",
    "\n",
    "for dataset in datasets:        \n",
    "    # Some of the datasets are not encoded in the default UTF-8.\n",
    "    if re.search(NO_HEADER, dataset):\n",
    "        data_raw = pd.read_csv(f\"{folder}/{dataset}\", encoding='latin-1', header = None)\n",
    "    else:\n",
    "        data_raw = pd.read_csv(f\"{folder}/{dataset}\", encoding='latin-1')\n",
    "        \n",
    "    data = data_raw.to_numpy()    \n",
    "    X, y = np.split(data, [-1], axis=1)\n",
    "\n",
    "    # Data imputation\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    X = imp.fit_transform(X)\n",
    "    # Min-max normalization to [0, 1]\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    # Extract general, statistical and information-theoretic measures\n",
    "    mfe = MFE(  groups=\"all\", \n",
    "                features=[\"one_itemset\", \"two_itemset\"], summary=[\"quantiles\"]\n",
    "    )\n",
    "    mfe.fit(X, y)\n",
    "    ft = mfe.extract()\n",
    "\n",
    "    #ft[0] represents headers, initialize once \n",
    "    if(columns == None):\n",
    "        columns = ft[0] \n",
    "        \n",
    "    # create file paths\n",
    "    filename, ext = dataset.rsplit('.', 1)\n",
    "    ft[1].insert(0, filename)    \n",
    "    row_data.append(ft[1])\n",
    "    \n",
    "    print(dataset)\n",
    "\n",
    "#add dataset to columns\n",
    "columns.insert(0, \"dataset\")\n",
    "metafeatures_df = pd.DataFrame(data=row_data, columns=columns)\n",
    "filename =  f\"./metafeatures_itemset.csv\"\n",
    "\n",
    "# Save data to CSV.\n",
    "metafeatures_df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Consolidation of Meta-Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The consolidated csv output contains the meta-features for each dataset and their corresponding evaluation following the result of the dataset labeling stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data containing information on general, statistical, information-theoretic, and complexity meta-features\n",
    "gsic = pd.read_csv('metafeatures_gsic.csv')\n",
    "gsic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data containing information on structural meta-features\n",
    "structural = pd.read_csv('metafeatures_itemset.csv')\n",
    "structural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consolidated meta-features\n",
    "mf_no_label = pd.concat([gsic, structural], axis=1, join='inner')\n",
    "mf_no_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation metrics derived from data labeling stage\n",
    "metrics =  pd.read_csv('dataset_labels/csv_collated/results_top_metrics.csv')\n",
    "metrics = metrics[['dataset', 'best_dist_metric_ari', 'best_dist_metric_dbs']]\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = pd.concat([mf_no_label, metrics], axis=1, join='inner')\n",
    "mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_data = mf.to_numpy()    \n",
    "X, y = np.split(mf_data, [-2], axis=1)\n",
    "\n",
    "# Data imputation\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X = imp.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = list(mf.columns.values)\n",
    "\n",
    "mf_final = pd.DataFrame(np.concatenate((X, y), axis=1))\n",
    "mf_final.columns = header\n",
    "mf_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_final.to_csv('dataset_labels/metafeatures.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_final = pd.read_csv('dataset_labels/metafeatures.csv')\n",
    "mf_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A copy of `metafeatures.csv` &mdash; where the abbreviated headers are expanded &mdash; is created. Its filename is `metafeatures_readable_header.csv`."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
